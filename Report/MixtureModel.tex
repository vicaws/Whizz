\section{Modelling Customer Behaviours}
\label{sec:model}

Customers' behaviour evolves over time as they respond to business offering and adjust to their own demand. We would like to represent the various behaviour dynamics of a collection of customers by panel data, and employ the Markov chain model to describe these data. In addition, we use the mixture model to find Markov states, each of which defines a partition of the behaviours observable within a single time interval.

\subsection{Representing Behaviours by Features}

A \textit{feature} is an individual measurable property of a behaviour being observed, and choosing informative features is crucial for effective clustering. For example, to measure how often the pupil uses Whizz online tutorial, we can define the time spent or number of visits within a month as the feature. For each customer, we define multiple features to capture his behaviours of various aspects within a time interval. Suppose we are interested in studying bahaviours of $n$ customers in $T$ discrete consecutive time periods, and define $m$ features, then we denote the feature data as a sequence:
\begin{equation}
\label{eq:customerJourney}
\left\lbrace \mathbf{X}_1, ~\mathbf{X}_2, ~\dots, ~\mathbf{X}_t, ~\dots, ~\mathbf{X}_T \right\rbrace,
\end{equation}
in which the $t$-th element $\mathbf{X}_t = (x_{ij}^t) \in \mathbb{R}^{m \times n}$ is a matrix for all $t=1,2,\dots,T$. In addition, we denote the features of customer $j$ at the $t$-th time interval by the $j$-th column of $\mathbf{X}_t$ by $\mathbf{x}_{tj} = [x_{1j}^t ~x_{2j}^t ~\cdots ~x_{mj}^t]^\top$.

\subsection{Customer Journeys and Markov Chain}

Customer journeys reflect their feature dynamics over time, denoted as (\ref{eq:customerJourney}). One practical challenge of computing such sequence of matrices is to resolve the inconsistency present in journeys of different customers. The inconsistency refers to the problem that the time intervals for different customers being alive in the services are not aligned, so that their features are not comparable. Moreover, it is highly likely to have significant missing information within specific time intervals for customers who have not yet entered the service or have already churned. To resolve the inconsistency, we align and aggregate customers' features by \textit{customer month} rather than calendar month. Doing so enables the effective modelling using Markov chain.

\subsubsection{Customer Month}

Splitting pupils' behaviours into monthly time periods makes most sense provided the business settings at Whizz. Pupils subscribe to access Whizz products on a 1-month contract, and make the choice to leave the service at the end of each subscription. If no action is taken, a renewal will be made by default.

Due to the inconsistency present in journeys of different customers, we align their features by switching the reference from calendar month to customer month. This is illustrated by an example in \Cref{fig:customerMonth}. It provides much cleaner and more sensible data for modelling task. 

\begin{figure}[!h]
\centering
\includegraphics[scale=.75]{CustomerMonth.png}
\caption{Change reference from calendar month to customer month. Customer A, B and C have very different journeys in the sense of subscription start and end dates. Each block represents customer's monthly features. Under calendar month reference, we have to choose studying months from March to August to cover all activities. This choice results in irregular temporal distribution of missing information for all 3 customers. After changing the reference to customer month, features are aligned by customer month and therefore comparable. Moreover, the missing information only occurs after the customer churns. It can also handle discontinuous subscriptions like the case of customer B.}
\label{fig:customerMonth}
\end{figure}

\subsubsection{Markov Chain - Dynamic Model for Behavioural Changes}

We assume that customers with intentions to churn exhibit different behaviours than others do. Behaviours are different distributionally, and generated from a finite number of \textit{states}. Then the discrete time behaviour of each customer results in a chain of states over time. This formulates into a discrete-time Markov chain with states transiting over time, where each state emits distinguishable behaviour distribution from others. An example is given in \Cref{fig:markovChain}.

\begin{figure}[!h]
\centering
\includegraphics[scale=.75]{Markov.png}
\caption{Behaviours emitted from Markov states. States $S_1$, $S_2$ and $S_3$ generate differently distributed behaviours. For example, $S_1$ generates $\{ B_1, ~B_2, ~B_4\}$ while $S_3$ produces $\{ B_1, ~B_4\}$. Even if the two states can generate the same set of behaviours, the emission probabilities can be different, thus still resulting in different behaviour distributions. States transit between each other over time stochastically.}
\label{fig:markovChain}
\end{figure}

Consider the behavioural journey of customer $j$, which is represented by a sequence of feature data $\{ \mathbf{x}_{tj} \}_{t=1}^{T}$. At time interval $t$, feature $\mathbf{x}_{tj}$ is an instance from a distribution generated by a state. Let's denote the time sequence of generative states as $\{ c_{tj} \}_{t=1}^{T}$. In a Markov chain setting the sequences are defined stochastically, with the next state being conditionally dependent on the present state, but not any further previous history. This is known as \textit{Markov property}. 







Markov State and Mixture Model

The goal is to assess the likelihood of customers canceling by examining their behaviors.

We model the behaviors of customers as the emission of Markov states, either hidden or observable. With this modelling assumption, we can also do temporal transitional analysis to gain insights of customers' dynamic behavioral change.

We can define states by some features.

We can also infer states from data through clustering task. To undertake the clustering task, we choose to use mixture model. 




Schematic plot showing the relations between states and behaviors.

Schematic plot showing temporal transition of states.

Verify the first order markov property (stationarity assumption, the generative stochastic process is itself time invariant, and thus the parameters describing all probabilistic transitions are themselves constant)


\subsection{Clustering Using Mixture Model}

\paragraph{Generative process}

\begin{equation}
\mathbb{P} (\mathbf{y}, \mathbf{c}, \bm \theta) = \prod_{k=1}^K G_0 (\theta_k) \prod_{n=1}^N F(y_n | \theta_{c_n}) P(c_n)
\end{equation}

\begin{itemize}
\item $\mathbf{y} = \{y_1, y_2, \cdots, y_N \}$, observations
\item $\mathbf{c} = \{c_1, c_2, \cdots, c_N \}$, cluster assignments
\item $\bm \theta = \{\theta_1, \theta_2, \cdots, \theta_K \}$, cluster parameters
\item $G_0(\theta)$, a prior over the cluster parameters
\item $P(c)$, a prior over the mixing distribution
\item $F(y_n|\theta_{c_n})$, a hypothetical distribution over the observations
\item Assumptions: each observation is conditionally independent given its latent cluster assignments and the cluster parameters
\end{itemize}

\paragraph{Posterior probability of assignments}

\begin{equation}
\mathbb{P} (\mathbf{c} | \mathbf{y}) = \frac{\mathbb{P}(\mathbf{y} | \mathbf{c}) P(\mathbf{c})}{\sum_{\mathbf{c}} \mathbb{P}(\mathbf{y} | \mathbf{c}) P(\mathbf{c})},
\end{equation}
where
\begin{equation}
\mathbb{P}(\mathbf{y} | \mathbf{c}) = \int_\theta \left[ \prod_{n=1}^N F(y_n | \theta_{c_n}) \prod_{k=1}^K G_0 (\theta_k) \right] \text{d} \theta
\end{equation}


BNP clustering assume that there is an infinite number of latent clusters (namely $K \rightarrow +\infty$), but that a finite number of them is used to generate the observed data. There are an infinite number of clusters, though a finite data set only exhibits a finite number of active clusters.

\subsection{Modelling Pipeline}

Feature extraction

Features distributional modelling

Fitting mixture model

Analytic (churn rate calculation, clusters interpretation)